{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Creating a model with Single GRU layer for 450 research paper abstracts (for testing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries and required datasets(450 AI/ML research papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\anaconda3\\envs\\virtualenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer, AdamWeightDecay, pipeline, create_optimizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import DefaultDataCollator\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version{}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r'arxivData.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains the total of 64838939 characters\n"
     ]
    }
   ],
   "source": [
    "#Load the text file\n",
    "text = open(data,'rb').read().decode(encoding='utf-8')\n",
    "print('Dataset contains the total of {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character to integer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'\\n':   0,\n",
      "'\\r':   1,\n",
      "' ' :   2,\n",
      "'!' :   3,\n",
      "'\"' :   4,\n",
      "'#' :   5,\n",
      "'$' :   6,\n",
      "'%' :   7,\n",
      "'&' :   8,\n",
      "\"'\" :   9,\n",
      "'(' :  10,\n",
      "')' :  11,\n",
      "'*' :  12,\n",
      "'+' :  13,\n",
      "',' :  14,\n",
      "'-' :  15,\n",
      "'.' :  16,\n",
      "'/' :  17,\n",
      "'0' :  18,\n",
      "'1' :  19,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('{:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'itle,year\\r\\n\"[{\\'name\\': \\'Ah'---char2int--- [75 86 78 71 14 91 71 67 84  1  0  4 61 93  9 80 67 79 71  9 28  2  9 35\n",
      " 74]\n"
     ]
    }
   ],
   "source": [
    "print('{}---char2int--- {}'.format(repr(text[38:63]), text_as_int[38:63]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not doing stemming and lemmatization because we need letters and special characters such as for raised to ^ sign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare Dataset\n",
    "\n",
    "We levarage a sliding window approach to train our model. We first set the maximum sequence length to 120 characters. This is done for the purpose of preparing and training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "u\n",
      "t\n",
      "h\n",
      "o\n",
      "r\n",
      ",\n",
      "d\n",
      "a\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of a sentence we want for a single input in characters\n",
    "seq_length = 120\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "#Create training examples\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'author,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,\"'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\"[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.00209v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http\"\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'://arxiv.org/pdf/1802.00209v1\\', \\'type\\': \\'application/pdf\\', \\'title\\': \\'pdf\\'}]\",2,\"We propose an architecture for VQA which '\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent a'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ttention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations bet'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ween several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset,'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "' performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmecha'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'nisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent '\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.\",\"[{\\'t'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\"erm': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/s\"\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)#?\n",
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'author,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,'\n",
      "Target data:  'uthor,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,\"'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      " input: 67 ('a')\n",
      " expected output: 87 ('u')\n",
      "Step    1\n",
      " input: 87 ('u')\n",
      " expected output: 86 ('t')\n",
      "Step    2\n",
      " input: 86 ('t')\n",
      " expected output: 74 ('h')\n",
      "Step    3\n",
      " input: 74 ('h')\n",
      " expected output: 81 ('o')\n",
      "Step    4\n",
      " input: 81 ('o')\n",
      " expected output: 84 ('r')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\" expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape=<BatchDataset element_spec=(TensorSpec(shape=(64, 120), dtype=tf.int32, name=None), TensorSpec(shape=(64, 120), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(\"Dataset Shape={}\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    Utility to create model object\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. This is basically in power of 2\n",
    "        rnn_units: number if GRU units to be used\n",
    "        batch_size: batch size for training model.\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)#softmax?\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lenth of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = vocab_size, embedding_dim = embedding_dim, rnn_units = rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           50432     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 197)           201925    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,190,661\n",
      "Trainable params: 4,190,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = r'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 64\n",
    "hostory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_checkpoints\\\\ckpt_256'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Build model using the function created above with the parameters\n",
    "\n",
    "Using model.summary we saw how the batch size shows up as one of the parametres which determined shape.\n",
    "For inference, we would be using a single input sentence/context to generate text.Thus we build the model again using buil_model utility we preprared earlier but use a batch_size of 1 this time. Once we have the model object with desired batch size, we use load_weights to utilize the latest checkpoint weights for instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (1, None, 256)            20480     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, None, 80)             82000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,040,784\n",
      "Trainable params: 4,040,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, context_string, num_generate=1000, temperature=1.0):\n",
    "    input_eval = [char2idx[s] for s in context_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (context_string + ''.join(text_generated))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature is scaling factor. It helps in controlling the output randomness of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Test model's text generation using seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are seberale, and e samplen and then in a cances of the sample is nemeat.\n",
      "\n",
      "It is impation is the sama\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples arequentiFy an3 (BuporiGable and siviomqAr)\n",
      "\n",
      "When(0. \n",
      "o4xan8 and Bizh $V&,5q6 w5 Dtimptrin a spumait-\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used at of s ald adults living in the sumbor of the semeat, a dataset when in a peprarente that the\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to represent the population is a bertain cance of the population is the sumber of observations\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to describe and summarize data.\n",
      "\n",
      "The mean is a table or graph that che and to mean is a meas\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to describe and summarize the semeat of the population is a table or grapustics of a sample of\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.32564))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to describe and summarize the population is the sumber of observations in the size of the popu\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.01)) #Best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to describe and summarize the population is a measure of the sample data. In the sample data. In the sample data. It is a way to measure the population is the sumber of observations in the size \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=200,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polulation and samples are used to describe and summarize the population is the sumber of observations in the size of the population is the sumber of observations in the size of the population is the sumber of observations in \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=200,temperature=0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Creating a model with single GRU layer for 25k research paper abstracts**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading data (25k papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99520</td>\n",
       "      <td>99520</td>\n",
       "      <td>99520.0</td>\n",
       "      <td>Multiplayer Performative Prediction: Learning ...</td>\n",
       "      <td>Learning problems commonly exhibit an intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70875</td>\n",
       "      <td>70875</td>\n",
       "      <td>70875.0</td>\n",
       "      <td>Estimating Vector Fields from Noisy Time Series</td>\n",
       "      <td>While there has been a surge of recent inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69168</td>\n",
       "      <td>69168</td>\n",
       "      <td>69168.0</td>\n",
       "      <td>3D-OES: Viewpoint-Invariant Object-Factorized ...</td>\n",
       "      <td>We propose an action-conditioned dynamics mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11441</td>\n",
       "      <td>11441</td>\n",
       "      <td>11441.0</td>\n",
       "      <td>Canonical Correlation Analysis for Analyzing S...</td>\n",
       "      <td>We propose using canonical correlation analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31746</td>\n",
       "      <td>31746</td>\n",
       "      <td>31746.0</td>\n",
       "      <td>Reducing Noise in GAN Training with Variance R...</td>\n",
       "      <td>We study the effect of the stochastic gradie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0         99520         99520     99520.0   \n",
       "1         70875         70875     70875.0   \n",
       "2         69168         69168     69168.0   \n",
       "3         11441         11441     11441.0   \n",
       "4         31746         31746     31746.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Multiplayer Performative Prediction: Learning ...   \n",
       "1    Estimating Vector Fields from Noisy Time Series   \n",
       "2  3D-OES: Viewpoint-Invariant Object-Factorized ...   \n",
       "3  Canonical Correlation Analysis for Analyzing S...   \n",
       "4  Reducing Noise in GAN Training with Variance R...   \n",
       "\n",
       "                                            abstract  \n",
       "0    Learning problems commonly exhibit an intere...  \n",
       "1    While there has been a surge of recent inter...  \n",
       "2    We propose an action-conditioned dynamics mo...  \n",
       "3    We propose using canonical correlation analy...  \n",
       "4    We study the effect of the stochastic gradie...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('df_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning problems commonly exhibit an intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While there has been a surge of recent inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We propose an action-conditioned dynamics mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We propose using canonical correlation analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We study the effect of the stochastic gradie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0    Learning problems commonly exhibit an intere...\n",
       "1    While there has been a surge of recent inter...\n",
       "2    We propose an action-conditioned dynamics mo...\n",
       "3    We propose using canonical correlation analy...\n",
       "4    We study the effect of the stochastic gradie..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removed all columns except abstract\n",
    "df = df.drop(df.columns[[0, 1, 2, 3]], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning problems commonly exhibit an intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While there has been a surge of recent inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We propose an action-conditioned dynamics mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We propose using canonical correlation analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We study the effect of the stochastic gradie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0    Learning problems commonly exhibit an intere...\n",
       "1    While there has been a surge of recent inter...\n",
       "2    We propose an action-conditioned dynamics mo...\n",
       "3    We propose using canonical correlation analy...\n",
       "4    We study the effect of the stochastic gradie..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\'', '\\'', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "df['abstract'] = df['abstract'].map(lambda x: x[2: -1])\n",
    "df['abstract'] = df['abstract'].map(lambda x: clean(x))\n",
    "text = df.to_string(index=False)\n",
    "text = clean(text)\n",
    "text = text[text.find(df.iloc[0]['abstract'][0:3]):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "' ' :   0,\n",
      "'!' :   1,\n",
      "'\"' :   2,\n",
      "'#' :   3,\n",
      "'$' :   4,\n",
      "'%' :   5,\n",
      "'&' :   6,\n",
      "\"'\" :   7,\n",
      "'(' :   8,\n",
      "')' :   9,\n",
      "'*' :  10,\n",
      "'+' :  11,\n",
      "',' :  12,\n",
      "'-' :  13,\n",
      "'.' :  14,\n",
      "'/' :  15,\n",
      "'0' :  16,\n",
      "'1' :  17,\n",
      "'2' :  18,\n",
      "'3' :  19,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('{:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'interesting feedback mech'---char2int--- [73 78 84 69 82 69 83 84 73 78 71  0 70 69 69 68 66 65 67 75  0 77 69 67\n",
      " 72]\n"
     ]
    }
   ],
   "source": [
    "print('{}---char2int--- {}'.format(repr(text[38:63]), text_as_int[38:63]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of a sentence we want for a single input in characters\n",
    "seq_length = 120\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "#Create training examples\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Learning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing deci'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'sion makers\\' actions. This paper formulates a new game theoretic framework for this phenomenon, called \"multi-player perf'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ormative prediction\". We focus on two distinct solution concepts, namely (i) performatively stable equilibria and (ii) Na'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'sh equilibria of the game. The latter equilibria are arguably more informative, but can be found efficiently only when th'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'e game is monotone. We show that under mild assumptions, the performatively stable equilibria can be found efficiently by'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "' a variety of algorithms, including repeated retraining and the repeated (stochastic) gradient method. We then establish '\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'transparent sufficient conditions for strong monotonicity of the game and use them to develop algorithms for finding Nash'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "' equilibria. We investigate derivative free methods and adaptive gradient algorithms wherein each player alternates betwe'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'en learning a parametric description of their distribution and gradient steps on the empirical risk. Synthetic and semi-s'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ynthetic numerical experiments illustrate the results. While there has been a surge of recent interest in learning differ'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ential equation models from time series, methods in this area typically cannot cope with highly noisy data. We break this'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "' problem into two parts: (i) approximating the unknown vector field (or right-hand side) of the differential equation, an'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'d (ii) dealing with noise. To deal with (i), we describe a neural network architecture consisting of tensor products of o'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ne-dimensional neural shape functions. For (ii), we propose an alternating minimization scheme that switches between vect'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'or field training and filtering steps, together with multiple trajectories of training data. We find that the neural shap'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'e function architecture retains the approximation properties of dense neural networks, enables effective computation of v'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ector field error, and allows for graphical interpretability, all for data/systems in any finite dimension $d$. We also s'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'tudy the combination of either our neural shape function method or existing differential equation learning methods with a'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'lternating minimization and multiple trajectories. We find that retrofitting any learning method in this way boosts the m'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\"ethod's robustness to noise. While in their raw form the methods struggle with 1% Gaussian noise, after retrofitting, the\"\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'y learn accurate vector fields from data with 10% Gaussian noise. We propose an action-conditioned dynamics model that pr'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'edicts scene changes caused by object and agent interactions in a viewpoint-invariant 3D neural scene representation spac'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'e, inferred from RGB-D videos. In this 3D feature space, objects do not interfere with one another and their appearance p'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ersists over time and across viewpoints. This permits our model to predict future scenes long in the future by simply \"mo'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ving\" 3D object features based on cumulative object motion predictions. Object motion predictions are computed by a graph'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\" neural network that operates over the object features extracted from the 3D neural scene representation. Our model's sim\"\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ulations can be decoded by a neural renderer into2D image views from any desired viewpoint, which aids the interpretabili'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ty of our latent 3D simulation space. We show our model generalizes well its predictions across varying number and appear'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ances of interacting objects as well as across camera viewpoints, outperforming existing 2D and 3D dynamics models. We fu'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'rther demonstrate sim-to-real transfer of the learnt dynamics by applying our model trained solely in simulation to model'\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(30):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Learning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing dec'\n",
      "Target data:  'earning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing deci'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      " input: 44 ('L')\n",
      " expected output: 69 ('e')\n",
      "Step    1\n",
      " input: 69 ('e')\n",
      " expected output: 65 ('a')\n",
      "Step    2\n",
      " input: 65 ('a')\n",
      " expected output: 82 ('r')\n",
      "Step    3\n",
      " input: 82 ('r')\n",
      " expected output: 78 ('n')\n",
      "Step    4\n",
      " input: 78 ('n')\n",
      " expected output: 73 ('i')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\" expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape=<BatchDataset element_spec=(TensorSpec(shape=(64, 120), dtype=tf.int32, name=None), TensorSpec(shape=(64, 120), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(\"Dataset Shape={}\".format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Build model based on the parameters specified below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    Utility to create model object\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. This is basically in power of 2\n",
    "        rnn_units: number if GRU units to be used\n",
    "        batch_size: batch size for training model.\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, \n",
    "            stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "#Lenth of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           25344     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 99)            101475    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,065,123\n",
      "Trainable params: 4,065,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = r'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/\", histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3737/3737 [==============================] - 268s 70ms/step - loss: 1.1827\n",
      "Epoch 2/10\n",
      "3737/3737 [==============================] - 310s 82ms/step - loss: 0.9765\n",
      "Epoch 3/10\n",
      "3737/3737 [==============================] - 334s 89ms/step - loss: 0.9539\n",
      "Epoch 4/10\n",
      "3737/3737 [==============================] - 357s 95ms/step - loss: 0.9467\n",
      "Epoch 5/10\n",
      "3737/3737 [==============================] - 355s 94ms/step - loss: 0.9468\n",
      "Epoch 6/10\n",
      "3737/3737 [==============================] - 353s 94ms/step - loss: 0.9528\n",
      "Epoch 7/10\n",
      "3737/3737 [==============================] - 356s 95ms/step - loss: 0.9731\n",
      "Epoch 8/10\n",
      "3737/3737 [==============================] - 353s 94ms/step - loss: 1.6183\n",
      "Epoch 9/10\n",
      "3737/3737 [==============================] - 357s 95ms/step - loss: 1.7201\n",
      "Epoch 10/10\n",
      "3737/3737 [==============================] - 356s 95ms/step - loss: 1.6246\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "hostory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Test model's text generation based on few seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Networks (ANN). It is the envaningly, deiffic Memony treandar invand boust-plaring has in hige satermane rit\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Convolutional Neural Networks\",num_generate=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative adversarial networks (GANs) have gained increasing popularity of the problem convex the model with the supportable that are complexity of the state-of-the-art mo\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Generative adversarial networks (GANs) have gained increasing popularity\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative adversarial networks (GANs) have gained increasing popularity of the patching the optimization are sublementations of and ther optification of learning models in\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Generative adversarial networks (GANs) have gained increasing popularity\",num_generate=100,temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its efficiency. Moreover, different stages of MKRL can be seamlessly integrated into\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Creating a model with single LSTM layer for 25k research paper abstracts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build model based on the layers specified below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    Utility to create model object\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. This is basically in power of 2\n",
    "        rnn_units: number if GRU units to be used\n",
    "        batch_size: batch size for training model.\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = vocab_size, embedding_dim = embedding_dim, rnn_units = rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           25344     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (64, None, 99)            101475    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,373,795\n",
      "Trainable params: 5,373,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs_SingleLSTMSoftMax/\", histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "3737/3737 [==============================] - 157s 41ms/step - loss: 1.1531 - accuracy: 0.6578\n",
      "Epoch 2/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.9956 - accuracy: 0.6999\n",
      "Epoch 3/16\n",
      "3737/3737 [==============================] - 156s 41ms/step - loss: 0.9598 - accuracy: 0.7098\n",
      "Epoch 4/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.9396 - accuracy: 0.7154\n",
      "Epoch 5/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.9260 - accuracy: 0.7193\n",
      "Epoch 6/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.9162 - accuracy: 0.7221\n",
      "Epoch 7/16\n",
      "3737/3737 [==============================] - 160s 42ms/step - loss: 0.9084 - accuracy: 0.7243\n",
      "Epoch 8/16\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.9025 - accuracy: 0.7260\n",
      "Epoch 9/16\n",
      "3737/3737 [==============================] - 154s 41ms/step - loss: 0.8977 - accuracy: 0.7274\n",
      "Epoch 10/16\n",
      "3737/3737 [==============================] - 153s 41ms/step - loss: 0.8936 - accuracy: 0.7286\n",
      "Epoch 11/16\n",
      "3737/3737 [==============================] - 152s 41ms/step - loss: 0.8901 - accuracy: 0.7296\n",
      "Epoch 12/16\n",
      "3737/3737 [==============================] - 153s 41ms/step - loss: 0.8872 - accuracy: 0.7305\n",
      "Epoch 13/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8849 - accuracy: 0.7311\n",
      "Epoch 14/16\n",
      "3737/3737 [==============================] - 159s 42ms/step - loss: 0.8827 - accuracy: 0.7317\n",
      "Epoch 15/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8811 - accuracy: 0.7322\n",
      "Epoch 16/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8795 - accuracy: 0.7327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d547b42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 16\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/32\n",
      "3737/3737 [==============================] - 155s 41ms/step - loss: 0.8781 - accuracy: 0.7331\n",
      "Epoch 18/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8769 - accuracy: 0.7334\n",
      "Epoch 19/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8760 - accuracy: 0.7337\n",
      "Epoch 20/32\n",
      "3737/3737 [==============================] - 159s 42ms/step - loss: 0.8751 - accuracy: 0.7340\n",
      "Epoch 21/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8744 - accuracy: 0.7342\n",
      "Epoch 22/32\n",
      "3737/3737 [==============================] - 162s 43ms/step - loss: 0.8739 - accuracy: 0.7343\n",
      "Epoch 23/32\n",
      "3737/3737 [==============================] - 160s 43ms/step - loss: 0.8732 - accuracy: 0.7345\n",
      "Epoch 24/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8729 - accuracy: 0.7346\n",
      "Epoch 25/32\n",
      "3737/3737 [==============================] - 155s 41ms/step - loss: 0.8725 - accuracy: 0.7347\n",
      "Epoch 26/32\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8723 - accuracy: 0.7348\n",
      "Epoch 27/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8719 - accuracy: 0.7349\n",
      "Epoch 28/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8719 - accuracy: 0.7348\n",
      "Epoch 29/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8719 - accuracy: 0.7349\n",
      "Epoch 30/32\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8720 - accuracy: 0.7348\n",
      "Epoch 31/32\n",
      "3737/3737 [==============================] - 160s 43ms/step - loss: 0.8719 - accuracy: 0.7348\n",
      "Epoch 32/32\n",
      "3737/3737 [==============================] - 162s 43ms/step - loss: 0.8720 - accuracy: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d543580d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "model.fit(dataset, epochs=EPOCHS, initial_epoch=16,callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test model's text generation based on the seeds given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its efficiency. Moreover, different stages of MKRL can be seamlessly integrated into\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its encrypted dataset to a semi-trusted cloud comparisons are paper, we present a ma\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are focused on the real-world data collected data containing the second positive resources spent in the\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.32564))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Creating a model using Generic transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Import and install required libraries and pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gymzTcmXo-e-",
    "outputId": "bd45c4d5-7867-4e7b-e13c-9bf7c33deab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xe9RLOswpGDl"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "061eb5df9f40423a839130eb9d858998",
      "12946c3b3b6e40ceb890643632337ddb",
      "1366da2fb52d400e8363f307db82b3b6",
      "5e39f9360aa147049578972c8c7e2cca",
      "e9994d8eef8e44d1bdce4c83e3184705",
      "434e3c1a0fdd4ea68515e1b475f57bab",
      "9eab650ee293425faae80985475b2149",
      "72456788328a48de85d35485895486f1",
      "0e886d60e1b14a44ab40785927adb13f",
      "517ebb37485a4df9b538799fb5977938",
      "3c2577087b1045b1b6a06fcd3f5e1474",
      "ef5ca03e696641aebae8e178e370f4e7",
      "16780d8f0f0f483d94ce1f936736fcee",
      "37b2bb59b317412ca1bb4acf37f68b44",
      "0f723c2639b74106a5afbefacef98e42",
      "02e9689ffc334ec9bd587e75113f4b0f",
      "ad07b65ce3c54d14960f8bd025892e4c",
      "8799ff69376f4441b6fa3aee9df8fe9f",
      "ffdc9f73a2ab4e008b1f450493076e2d",
      "f63e885995dc4375ac16523763ca0a0e",
      "dde4be8cf952429cb7303f529e9d435c",
      "fcfa35eb98be408a82baff6eb0661a4a",
      "ce1828cc8c1d49fa842297117dbf9942",
      "487ce6476448426a8aa52975c54e873c",
      "7324f99e76ea4e7f9e24cf68990decbb",
      "b6a5ecf2974148aa856ba60cc5229ade",
      "7ce5f8dba9d949f9b2802ded949f1053",
      "ec9e6ff003f843dd9a4c5d6c19b6345d",
      "af154043c7a44ce196fc1ec151b5a6dc",
      "6a515e51b222426cac66730a8c524a62",
      "365d34a4d2cb49a1981d49207af55cf3",
      "e789873ec42c437397f94ac5e964077d",
      "241caf8bfac34b0eb98868499b983c33",
      "55e7ad30d83c4626adc6f6bf5928ed0b",
      "7428e847435044f7a619fdceb56fe313",
      "527eb1df093849aabf525930658941cc",
      "2937e0f3732d48478649645492d3e7d8",
      "93a8a0d6bae843c6b4eb8c52872cb4e0",
      "9e08cb60f4c24653a27b53616b06ebf2",
      "5117b82dbe0d4420b300db6b3f910572",
      "28f0a600ada343d98d5b2eded0a1f8a3",
      "701e1926d7fa4a4e9cc64757383b8a22",
      "c84af6c750b34b2c9f91c7afddabe795",
      "7fa72fd9dde544059c859741ae4da6f4",
      "d54d05833ce04326904f3fb0cbd6df82",
      "ae41dade0bd946a98a43c7a4f028c4e5",
      "78e06957ed0b43cf9d843dfd354c4227",
      "6da1b50a3edc4ec3bcbb7828459b6ae5",
      "d41c40f7c89142f6b3cdcdac1dc1a674",
      "692d6396e7184bcabba40dec16c226fd",
      "c27495a0b6f340fcb96281404a238a90",
      "cc90f44907674ac1877f56e17cfab630",
      "72e9f00618094e7eb425beff32f5c185",
      "ad44a23063ab413ca537dee65ada899f",
      "349e3a14926d41abae94c7e5215daa5d"
     ]
    },
    "id": "KB-yHstbph-z",
    "outputId": "a8999f9a-2ae9-4f02-c187-dc114e81b85b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061eb5df9f40423a839130eb9d858998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5ca03e696641aebae8e178e370f4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1828cc8c1d49fa842297117dbf9942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e7ad30d83c4626adc6f6bf5928ed0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d05833ce04326904f3fb0cbd6df82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnBocsKEqWOr"
   },
   "outputs": [],
   "source": [
    "text = \"Multisensory object-centric perception\"\n",
    "encoded_input = tokenizer.encode(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HM_o5eQtV_D",
    "outputId": "e85dec6a-68ea-40d0-c4d4-8a1748b71870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15205,   271,   641,   652,  2134,    12, 28577, 11202]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OwBoYigqtnbh",
    "outputId": "8e8f01de-ae15-4f04-8298-5e4e6d5b23c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mult'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test model's text generation based on the seeds given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asSZ5u_MqsGL",
    "outputId": "8474ac88-a31b-4459-db16-0d4a16ddbda5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded_input, max_length=200, num_beams=5, no_repeat_ngram_size=2, early_stopping=True) #Beam algorith to predict the next word # ngram is taking two two words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "mN8jEIQxt--8",
    "outputId": "0e36a59d-4466-4468-a41a-2db055cecb9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Multisensory object-centric perception.\\n\\nIn this article, we will look at some of the most important aspects of visual perception and how they can be used to improve your perception of your surroundings. We will also discuss how you can use this knowledge to help you better understand the world around you.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Creating a model using DistilGPT2 transformer (Transfer Learning Model)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Import and install required libraries and pretrained model (DistilGPT-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for the fine-tuning operation is available on the Huggingface Hub, and it’s a subset of a bigger dataset hosted on Kaggle.\n",
    "\n",
    "The original dataset, published by Cornell University, contains titles and abstracts of 1.7M+ scientific papers belonging to the STEM category. The subset hosted on the Huggingface Hub contains information on around 100K papers pertaining to the machine learning category.\n",
    "\n",
    "I decided to fine-tune DistilGPT-2 on abstracts only. I started by loading the dataset from the Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\n",
      "Found cached dataset csv (C:/Users/gupta/.cache/huggingface/datasets/CShorten___csv/CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "    num_rows: 117592\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"CShorten/ML-ArXiv-Papers\", split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Preprocessing (Train-test split, tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5fcced655579dd43.arrow and C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-10bb285727aaa68b.arrow\n"
     ]
    }
   ],
   "source": [
    "data = data.train_test_split(shuffle = True, seed = 200, test_size=0.2)\n",
    "\n",
    "train = data[\"train\"]\n",
    "val = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-cf1610aeae1e7e01.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-43ea478b4774c95d.arrow\n"
     ]
    }
   ],
   "source": [
    "# The tokenization function\n",
    "def tokenization(data):\n",
    "    tokens = tokenizer(data[\"abstract\"], padding=\"max_length\", truncation=True, max_length=300)\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenizer in batch mode and drop all the columns except the tokenization result\n",
    "train_token = train.map(tokenization, batched = True, remove_columns=[\"title\", \"abstract\", \"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "val_token = val.map(tokenization, batched = True, remove_columns=[\"title\", \"abstract\", \"Unnamed: 0\", \"Unnamed: 0.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-342d0ad02f377fc9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-7792641a8a9d718a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-525c02bbc6880d8e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b46ee8c7167b3efe.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f582ebc76c869bce.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-da19e43f09b21f24.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-730ee5d0d0b6aa48.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f667c8c4d512be97.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b79f821764aa1984.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-fff392312a41c0ca.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-57f91f812a7ceb0c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-4cbf7e6d241f03b2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-c9818697c8ecadb2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-102709533881cc2e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-59bbf7fed094aaae.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-1c1982eac4815767.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-a731bbf2af533f46.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5e0e7a1f8474f269.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-966dfab3ec95cc7b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-755cae0a538e9147.arrow\n"
     ]
    }
   ],
   "source": [
    "# Create labels as a copy of input_ids\n",
    "def create_labels(text):\n",
    "    text[\"labels\"] = text[\"input_ids\"].copy()\n",
    "    return text\n",
    "\n",
    "# Add the labels column using map()\n",
    "lm_train = train_token.map(create_labels, batched=True, num_proc=10)\n",
    "lm_val = val_token.map(create_labels, batched=True, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = model.prepare_tf_dataset(\n",
    "    lm_train,\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "validation_set = model.prepare_tf_dataset(\n",
    "    lm_val,\n",
    "    shuffle=False,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Compile the model using optimizers and our input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0005,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.95,\n",
    "    staircase=False)\n",
    "    \n",
    "# Exponential decay learning rate\n",
    "optimizer = AdamWeightDecay(learning_rate=lr_schedule, weight_decay_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 81912576  \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,912,576\n",
      "Trainable params: 81,912,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11759/11759 [==============================] - 3533s 300ms/step - loss: 2.4148 - accuracy: 0.2275 - val_loss: 2.2005 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21de74063a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit with callbacks\n",
    "model.fit(train_set, validation_data=validation_set, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"tf\",\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Testing the model's text generation using variable input seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\anaconda3\\envs\\virtualenv\\lib\\site-packages\\transformers\\generation\\tf_utils.py:603: UserWarning:\n",
      "\n",
      "You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'clustering of high-dimensional data requires data-driven models that\\ncapture the intrinsic properties of data. To develop such models which are\\nreliable in data due to their complex relationships to dimensionality, the\\nalgorithm for unsupervised classification of high-dimensional data has\\nrecently been proposed. The proposed approach relies on a novel deep\\nconvolutional neural network to learn how to effectively learn to\\nlearn from small number of observations, such as from a single low-level\\nsensor for example. The proposed network combines a convolutional neural\\nnetwork that learns to segment the data by introducing a graph with\\ndifferent weights, as observed in image reconstruction. The results\\nshow the superior performance of our approach using multiple benchmarks\\nand image data sets with different structural properties, and an\\napplication to an urban-scale data set. All code and data are available at\\nhttps://github.com/lun/sustainablenetwork.\\n'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"clustering\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The memory characteristic of the proposed recurrent attention units are\\nthat they are initialized to be connected to the same input sequence. The\\nimportance of this type of mechanism in recurrent neural networks has been\\nevaluated in terms of generalization error while it has been widely recognized\\nthat it can be thought of as an important and necessary mechanism to achieve\\nbetter learning performance than conventional recurrent attention units. In\\nthis study, inspired by the idea of neural networks in the deep learning\\ncommunity, we propose a novel RNN learning architecture based on a simple yet\\nimportant feature of recurrent deep learning, named the residual attention unit. The\\nproposed deep residual attention unit architecture comprises two modules,\\nwhich consists of the fully connected LSTM-like layer with the attention unit\\nlayers, the first module which produces a feature representation by a novel deep\\ncontrastive divergence based on different recurrent layers. The second module\\nis a combination of a fully connected LSTM layer with a residual attention unit\\nmodule to deal with the long term temporal dependencies in RNN's\\nstructure. The proposed architecture is evaluated on the CIFAR10 and\\nCIFAR100 datasets and various RNN models, including three well-known,\\narchitecture-changing baselines. Compared to the state-of-the-art\\nproposed architecture, the proposed architecture can be used as an initial\\ninitial input and can be used as input in any RNN model pre-possible\\nfor each task. We demonstrate the superior performance compared to the conventional\\nlayers in terms of the model's prediction accuracy in different scenarios as well as other time window sizes and\\nsimultaneously. As the obtained results revealed via our proposed architecture\\nshow that our proposed architecture can more effectively encode and maintain the same type of attention\\nunits at different time-granular patterns.\\nwith only a less complex layers.\\nparameters for each RNN's topologies, compared to RNN that lead to the original convolutional recurrent output layer is more appropriate RNN, and its more\\nattention unit than in different levels.\\narchitecture or skip connections is able to the deep residual attention units can have lesser\\n\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"The memory characteristic of the proposed recurrent attention units are\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'enchanced meta-heuristic (ML-ACO) that combines the multi-armed bandit\\n(MAB) model to achieve improved return are a promising direction despite their\\nhigh computational cost and computational time. However, it is still unclear\\nwhether MAB in certain ML-ACO scenarios performs sufficiently well for\\ngeneralized users and/or in specific ML applications. To solve this problem\\nwe propose an ML-ACO model that is more general and versatile than the\\nmulti-armed bandit bandit model (MAB). Our contribution is to derive a principled\\nframework that incorporates both MAB and existing bandit algorithms with a\\nnovel strategy to improve the performance of the performance of the\\nmulti-armed online gradient descent algorithm at hand. Nested with the proposed\\nalgorithms and experimental results, we demonstrate that our proposed\\napproach outperforms all previous algorithms by significant margins.\\n'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"enchanced meta-heuristic (ML-ACO) that combines\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Deep reinforcement learning has emerged as a powerful method for solving\\nsequential control tasks. However, in some applications the number of trained\\ndeep Q-networks and task-relevant features often remains a large challenge. For\\ninstance, high performance deep reinforcement learning architectures like Montezuma's\\nQ-learning often make it difficult to deploy such architectures on\\nresource-poor systems like GPUs. These limitations complicate deep Q-network\\nlearning, especially in the low resource regime which can achieve higher\\nconvergence, e.g. from one GPU. One way to address these limitations is\\nto train multi-layer Q-networks that are capable of efficiently learning joint\\nstructures across different tasks, with high-quality outputs. We present\\nan RL-based method to solve a variety of complex tasks in this low resource region\\nthat can be considered a single Q-network with lower computational cost and\\nperformance loss. Specifically, we investigate how to train a multi-layer Q-network\\nfor such tasks through reinforcement learning. For each task, our\\nrepresentation is learned by optimizing a deep Q-network to produce an\\nout-of-distribution mapping that achieves high-quality outputs. We evaluate\\nthis method on the challenging MuJoCo environment, where state-of-the-art\\nQ-networks achieve high performance on these tasks.\\n\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"Deep reinforcement learning\"\n",
    "text_generator(test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3e12402ff69166de391f2510b5907624ba45d1b821ed425212530cae4040263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
